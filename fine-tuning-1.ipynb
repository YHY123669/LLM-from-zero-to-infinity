{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d4635f",
   "metadata": {},
   "source": [
    "文本分类任务的微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca63666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.5\n",
      "numpy version: 2.3.2\n",
      "tiktoken version: 0.11.0\n",
      "torch version: 2.8.0+cu129\n",
      "tensorflow version: 2.20.0\n",
      "pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"matplotlib\",\n",
    "    \"numpy\",\n",
    "    \"tiktoken\",\n",
    "    \"torch\",\n",
    "    \"tensorflow\",\n",
    "    \"pandas\"\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfb4ce",
   "metadata": {},
   "source": [
    "准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dce2757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv alreadt exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url,zip_path,extracted_path,data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} alreadt exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path,\"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path,data_file_path)\n",
    "    print(f\"File download and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url,zip_path,extracted_path,data_file_path)\n",
    "except (urllib.error.HTTPError,urllib.error.URLError,TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Try backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b91e7ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path,sep=\"\\t\",header=None,names=[\"Label\",\"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fcfe79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc6ee0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataest(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam,random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset,df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataest(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f834feef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\":0,\"spam\":1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f336e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义函数将数据集随机划分成训练集，验证集，测试集\n",
    "def random_split(df,train_frac,validation_frac):\n",
    "    df = df.sample(frac=1,random_state=123).reset_index(drop=True)#sample对数据集进行抽样，抽样率100%，作用是打乱原有的数据顺序；reset_index：重新整理被打乱的行号\n",
    "    #计算切分数据集的位置\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    #切分数据集\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df,validation_df,test_df\n",
    "train_df,validation_df,test_df = random_split(balanced_df,0.7,0.1)\n",
    "#将切分结果保存到磁盘\n",
    "train_df.to_csv(\"train.csv\",index=None)\n",
    "validation_df.to_csv(\"validation.csv\",index=None)\n",
    "test_df.to_csv(\"test.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae59381",
   "metadata": {},
   "source": [
    "创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a537c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "#由于文本消息长度不太，如果需要在一个batch内放多条数据，则需要把所有文本填充到最长文本的长度\n",
    "#选择 <|endoftext|> 作为填充字符\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1226b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self,csv_file,tokenizer,max_length=None,pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "\n",
    "        self.encoded_texts = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (torch.tensor(encoded,dtype=torch.long),torch.tensor(label,dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "286d588f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(train_dataset.max_length)\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(val_dataset.max_length)\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e08bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n",
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(\"Train loader:\")\n",
    "for input_batch,target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\",input_batch.shape)\n",
    "print(\"Label batch dimensions:\",target_batch.shape)\n",
    "\n",
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783dc10",
   "metadata": {},
   "source": [
    "使用预训练权重初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6b2a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\":50257,\n",
    "    \"context_length\":1024,\n",
    "    \"drop_rate\":0.0,\n",
    "    \"qkv_bias\":True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\":{\"emb_dim\":768,\"n_layers\":12,\"n_heads\":12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"],(\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"'max_length={BASE_CONFIG['context_length']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2fdd140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel,load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings,params = download_and_load_gpt2(model_size=model_size,models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model,params)\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ea97075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work.\n",
      "\n",
      "The second step is to understand the importance of your work.\n",
      "\n",
      "The third step is to understand the importance of your work.\n",
      "\n",
      "The fourth step is\n"
     ]
    }
   ],
   "source": [
    "#模型检查，检查模型是否可以生成连贯的文本，确保模型正确加载\n",
    "from previous_chapters import (generate_text_simple,text_to_token_ids,token_ids_to_text)\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1,tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "766a3f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' o 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' o 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "#模型检查，是否可以通过提示来判断垃圾邮件，结果表明模型的指令遵循并不理想，因为只进行了预训练\n",
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' o 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2,tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bb556",
   "metadata": {},
   "source": [
    "增加一个分类头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e17c89cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#查看模型框架\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8cb6a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#任务是替换和微调输出层：先冻结模型，将所有层设为不可训练\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#替换输出层\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"],out_features=num_classes)\n",
    "\n",
    "#设置最后一个transfromer块和输出层以及之间的layernorm层为可训练\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b77d7e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "663dc7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\",inputs)\n",
    "print(\"Inputs dimensions:\",inputs.shape)# shape:(batch_size,num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5f54004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimension: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\",outputs)\n",
    "print(\"Outputs dimension:\",outputs.shape)# shape:(batch_size,num_tokens,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ba02933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\",outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecec353",
   "metadata": {},
   "source": [
    "计算分类损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "765874d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:,-1,:],dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\",label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3540c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:,-1,:]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\",label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1518c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义计算准确率的函数\n",
    "def calc_accuracy_loader(data_loader,model,device,num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions,num_examples = 0,0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    \n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i <num_batches:\n",
    "            input_batch,target_batch = input_batch.to(device),target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:]\n",
    "            predicted_labels = torch.argmax(logits,dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b8444a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "#对为微调的模型计算分类准确度\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader,model,device,num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader,model,device,num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader,model,device,num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5516676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义计算分类损失的函数\n",
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch,target_batch = input_batch.to(device),target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits,target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c1fde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "\n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abc83dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device,num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device,num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader,model,device,num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515fd56",
   "metadata": {},
   "source": [
    "在监督数据上微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b89542d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter):\n",
    "    train_losses,val_losses,train_accs,val_accs = [],[],[],[]\n",
    "    examples_seen,global_step = 0,-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss,val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}):\"\n",
    "                      f\"Train loss {train_loss:.3f},Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        train_accuracy = calc_accuracy_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \",end=\"\")\n",
    "        print(f\"validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses,val_losses,train_accs,val_accs,examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fc1150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dac57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000):Train loss 2.153,Val loss 2.392\n",
      "Ep 1 (Step 000050):Train loss 0.617,Val loss 0.637\n",
      "Ep 1 (Step 000100):Train loss 0.523,Val loss 0.557\n",
      "Training accuracy: 70.00% | validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150):Train loss 0.561,Val loss 0.489\n",
      "Ep 2 (Step 000200):Train loss 0.419,Val loss 0.397\n",
      "Ep 2 (Step 000250):Train loss 0.409,Val loss 0.353\n",
      "Training accuracy: 82.50% | validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300):Train loss 0.333,Val loss 0.320\n",
      "Ep 3 (Step 000350):Train loss 0.340,Val loss 0.306\n",
      "Training accuracy: 90.00% | validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400):Train loss 0.136,Val loss 0.200\n",
      "Ep 4 (Step 000450):Train loss 0.153,Val loss 0.132\n",
      "Ep 4 (Step 000500):Train loss 0.222,Val loss 0.137\n",
      "Training accuracy: 100.00% | validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550):Train loss 0.207,Val loss 0.143\n",
      "Ep 5 (Step 000600):Train loss 0.083,Val loss 0.074\n",
      "Training accuracy: 100.00% | validation accuracy: 97.50%\n",
      "Training completed in 0.59 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=5e-5,weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "train_losses,val_losses,train_accs,val_accs,examples_seen = train_classifier_simple(\n",
    "    model,train_loader,val_loader,optimizer,device,num_epochs=num_epochs,eval_freq=50,eval_iter=5,)\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e41eaa",
   "metadata": {},
   "source": [
    "绘制loss图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96f0a200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen,examples_seen,train_values,val_values,label=\"loss\"):\n",
    "    fig,ax1 = plt.subplots(figsize=(5,3))\n",
    "\n",
    "    ax1.plot(epochs_seen,train_values,label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen,val_values,linestyle=\"-.\",label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen,train_values,alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0,examples_seen,len(train_losses))\n",
    "plot_values(epochs_tensor,examples_seen_tensor,train_losses,val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "198fc845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 98.75%\n",
      "Validation accuracy: 98.75%\n",
      "Test accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader,model,device,num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader,model,device,num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader,model,device,num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226803a",
   "metadata": {},
   "source": [
    "将LLM用作垃圾邮件分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fcd3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text,model,tokenizer,device,max_length=None,pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length,supported_context_length)]\n",
    "    assert max_length is not None,(\n",
    "        \"max_length must be specified. If you want to use the full model context,\"\n",
    "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
    "    )\n",
    "    assert max_length <= supported_context_length,(\n",
    "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
    "    )\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids,device=device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:,-1,:]\n",
    "    predicted_label = torch.argmax(logits,dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "892a3410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "print(classify_review(text_1,model,tokenizer,device,max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e28a6d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "print(classify_review(text_2,model,tokenizer,device,max_length=train_dataset.max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2717e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ab5e2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\",map_location=device,weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e2cdf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "print(classify_review(text_1,model,tokenizer,device,max_length=train_dataset.max_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
