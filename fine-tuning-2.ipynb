{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8795bb",
   "metadata": {},
   "source": [
    "Finetuning to follow instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0807196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.3.2\n",
      "matplotlib version: 3.10.5\n",
      "tiktoken version: 0.11.0\n",
      "torch version: 2.8.0+cu129\n",
      "tqdm version: 4.67.1\n",
      "tensorflow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # 绘图库\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # 进度条\n",
    "    \"tensorflow\",  # For OpenAI's pretrained weights\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7145d72",
   "metadata": {},
   "source": [
    "Preparing a dataset for supervised instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c75925f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n",
      "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "# 下载和加载数据集\n",
    "def download_and_load_file(file_path,url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path,\"w\",encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path,\"r\",encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path,url)\n",
    "print(\"Number of entries:\",len(data))\n",
    "print(data[0])#数据格式为 Alpaca 风格，包含 instruction 、 input(可选) 、 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d41e4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# 格式化输入数据，修改为模型学习的标准格式\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text\n",
    "model_input = format_input(data[50])\n",
    "desired_reponse = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ee474b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\",len(train_data))\n",
    "print(\"Validation set length:\",len(val_data))\n",
    "print(\"Test set length:\",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df99de2",
   "metadata": {},
   "source": [
    "Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48ebcae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self,data,tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))# 将拼接好的完整文本进行编码并添加到 encoded_texts\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return self.encoded_texts[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "403d343e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b71bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只生成 input ，没有 target\n",
    "def custom_collate_draft_1(batch,pad_token_id=50256,device=\"cuda\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]#在句末添加一个结束符\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))#添加结束符保证一个 batch 内所有样本长度一致\n",
    "        inputs = torch.tensor(padded[:-1])# 输入 inputs 是从第一个token到倒数第二个token\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fefc85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 input 和 target ，但会计算填充部分的 loss ，造成误差\n",
    "def custom_collate_draft_2(batch,pad_token_id=50256,device=\"cuda\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst,targets_lst = [],[]\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])# 输入 inputs 是从第一个token到倒数第二个token\n",
    "        targets = torch.tensor(padded[1:])# 目标 targets 是从第二个token到最后一个token\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor,targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "169450a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略填充部分的 loss ，pytorch 交叉熵会忽略标签为-100的位置\n",
    "def custom_collate_fn(batch,pad_token_id=50256,ignore_index=-100,allowed_max_length=None,device=\"cuda\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst,targets_lst = [],[]\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        #如果超过一个填充符，则把第一个填充符之外的填充符都替换为-100\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor,targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37e5eafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]], device='cuda:0')\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "inputs = custom_collate_draft_1(batch)\n",
    "print(inputs)\n",
    "inputs,targets = custom_collate_draft_2(batch)\n",
    "# print(inputs)\n",
    "print(targets)\n",
    "inputs,targets = custom_collate_fn(batch)\n",
    "# print(inputs)\n",
    "print(targets)\n",
    "#将填充符ID从 50256 切换为 -100 的意义是减少计算 loss 值的误差，下面的代码用于验证这样做的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e39f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "tensor(0.7936)\n",
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0,1.0],\n",
    "    [-0.5,1.5]]\n",
    ")\n",
    "targets_1 = torch.tensor([0,1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1,targets_1)\n",
    "\n",
    "logits_2 = torch.tensor(\n",
    "    [[-1.0,1.0],\n",
    "     [-0.5,1.5],\n",
    "     [-0.5,1.5]]\n",
    ")\n",
    "targets_2 = torch.tensor([0,1,1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2,targets_2)\n",
    "\n",
    "targets_3 = torch.tensor([0,1,-100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2,targets_3)\n",
    "\n",
    "print(loss_1)\n",
    "print(loss_2)\n",
    "print(loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb029a",
   "metadata": {},
   "source": [
    "Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b35add93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "\n",
    "from functools import partial\n",
    "# partial 可以将一个函数的某些参数固定下来，生成一个新的、更简单的函数\n",
    "customized_collate_fn = partial(custom_collate_fn,device=device,allowed_max_length=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fb868ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data,tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,#打乱数据顺序\n",
    "    drop_last=True,#丢弃不够一个完整 batch 的数据\n",
    "    num_workers=num_workers\n",
    ")\n",
    "val_dataset = InstructionDataset(val_data,tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "test_dataset = InstructionDataset(test_data,tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "print(\"Train loader:\")\n",
    "for inputs,targets in train_loader:\n",
    "    print(inputs.shape,targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25d3059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69826ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7497c1",
   "metadata": {},
   "source": [
    "Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f964550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e1dbf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "#测试当前模型的指令跟随效果\n",
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=50,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids,tokenizer)\n",
    "\n",
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ada78",
   "metadata": {},
   "source": [
    "Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07a46082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.167139339447021\n",
      "Validation loss: 4.050935411453247\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device,num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device,num_batches=5)\n",
    "\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdacb96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
      "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.570\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.002\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
      "Ep 1 (Step 000035): Train loss 0.877, Val loss 0.951\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
      "Ep 1 (Step 000055): Train loss 0.924, Val loss 0.893\n",
      "Ep 1 (Step 000060): Train loss 0.873, Val loss 0.877\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.856\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
      "Ep 1 (Step 000095): Train loss 0.653, Val loss 0.821\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
      "Ep 1 (Step 000110): Train loss 0.719, Val loss 0.799\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is an instruction that describes a task.\n",
      "Ep 2 (Step 000120): Train loss 0.592, Val loss 0.790\n",
      "Ep 2 (Step 000125): Train loss 0.626, Val loss 0.801\n",
      "Ep 2 (Step 000130): Train loss 0.583, Val loss 0.788\n",
      "Ep 2 (Step 000135): Train loss 0.547, Val loss 0.791\n",
      "Ep 2 (Step 000140): Train loss 0.580, Val loss 0.789\n",
      "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
      "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.780\n",
      "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.784\n",
      "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
      "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.781\n",
      "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
      "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
      "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
      "Ep 2 (Step 000205): Train loss 0.479, Val loss 0.724\n",
      "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.725\n",
      "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.733\n",
      "Ep 2 (Step 000220): Train loss 0.413, Val loss 0.738\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
      "Training completed in 0.94 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d8f47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf55413c",
   "metadata": {},
   "source": [
    "Extracting and saving response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a4ae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text,tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "474f0ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [00:31<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i,entry in tqdm(enumerate(test_data),total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text,tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\",\"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\",\"w\") as file:\n",
    "    json.dump(test_data,file,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065e4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a horse.'}\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbc1d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]','',CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(),file_name)\n",
    "print(f\"Model saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20204e50",
   "metadata": {},
   "source": [
    "Evaluating the finetuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c579b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama running: True\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "# 检查 Ollama 服务\n",
    "def check_if_running(process_name):\n",
    "    running = False\n",
    "    for proc in psutil.process_iter([\"name\"]):\n",
    "        if process_name in proc.info[\"name\"]:\n",
    "            running = True\n",
    "            break\n",
    "    return running\n",
    "\n",
    "ollama_running = check_if_running(\"ollama\")\n",
    "\n",
    "if not ollama_running:\n",
    "    raise RuntimeError(\"Ollama not running.Launch ollama before proceeding.\")\n",
    "print(\"Ollama running:\",check_if_running(\"ollama\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b7cd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path = \"instruction-data-with-response.json\"\n",
    "\n",
    "with open(file_path,\"r\") as file:\n",
    "    test_data = json.load(file)\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5528f53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
      "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
      "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories and low in fiber.\n",
      "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach. These treats are great for providing essential vitamins and minerals.\n",
      "5. Minerals: Llamas need access to mineral supplements, which can include salt, calcium, and phosphorus. These minerals help maintain their overall health and strong bone structure.\n",
      "\n",
      "In the wild, llamas might also eat:\n",
      "\n",
      "1. Leaves: They'll munch on leaves from trees and shrubs, like willow or cedar.\n",
      "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or birch.\n",
      "3. Mushrooms: Some species of mushrooms are safe for llamas to consume.\n",
      "\n",
      "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "    ):\n",
    "    data = {\n",
    "        \"model\":model,\n",
    "        \"messages\":[\n",
    "            {\"role\":\"user\",\"content\":prompt}\n",
    "        ],\n",
    "        \"options\":{\n",
    "            \"seed\":123,\n",
    "            \"temperature\":0,\n",
    "            \"num_ctx\":2048\n",
    "        }\n",
    "    }\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\",\"application/json\")\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "    return response_data\n",
    "\n",
    "model = \"llama3\"\n",
    "result = query_model(\"What do Llamas eat?\",model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3074df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "\n",
      "Score:\n",
      ">> I'd rate the model response \"The car is as fast as a horse.\" an 80 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The response uses a simile correctly, comparing the speed of the car to that of a horse.\n",
      "* The comparison is reasonable and relatable, as horses are known for their speed.\n",
      "* However, the model could have chosen a more vivid or unexpected comparison to make the sentence more engaging. For example, \"The car is as fast as a cheetah\" might be an even better simile.\n",
      "\n",
      "Overall, the response is good but not exceptional, which is why I'd give it an 80 out of 100.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "\n",
      "Score:\n",
      ">> I'd rate this model response a 0 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The instruction asks about the type of cloud associated with thunderstorms.\n",
      "* The model response completely misinterprets the question and provides an answer that has no relation to clouds or weather phenomena (tropical rainforest).\n",
      "* There is no attempt to provide any relevant information or context related to the original question.\n",
      "\n",
      "Overall, this response is not even close to being correct, which is why I'd give it a score of 0.\n",
      "\n",
      "-------------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "\n",
      "Score:\n",
      ">> I'd rate this model response a 0 out of 100.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "* The correct answer is Jane Austen, not Robert Frost.\n",
      "* Robert Frost was an American poet, and his works are known for their rural settings and exploration of themes such as nature, isolation, and the human condition. He has no connection to the novel \"Pride and Prejudice\".\n",
      "* The response is completely incorrect and does not demonstrate any understanding of the original instruction or the correct answer.\n",
      "\n",
      "Therefore, I would give this model response a score of 0 out of 100, indicating that it is entirely inaccurate and fails to meet the requirements of the task.\n",
      "\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "#构建打分提示词\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Given the input `{format_input(entry)}` \"\n",
    "        f\"and correct output `{entry['output']}`, \"\n",
    "        f\"score the model response `{entry['model_response']}`\"\n",
    "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "    )\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry[\"model_response\"])\n",
    "    print(\"\\nScore:\")\n",
    "    print(\">>\", query_model(prompt))\n",
    "    print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a45317d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|██████████| 110/110 [04:55<00:00,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 32.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#批量打分并计算模型平均分\n",
    "def generate_model_scores(json_data,json_key,model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data,desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input '{format_input(entry)}' \"\n",
    "            f\"and correct output '{entry['output']}', \"\n",
    "            f\"score the model response '{entry[json_key]}' \"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt,model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "    return scores\n",
    "\n",
    "scores = generate_model_scores(test_data,\"model_response\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
