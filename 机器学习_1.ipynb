{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4915bc82",
   "metadata": {},
   "source": [
    "所需 python 依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb63c466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm version: 4.67.1\n",
      "numpy version: 2.3.2\n",
      "torch version: 2.8.0+cu129\n",
      "pandas version: 2.3.1\n",
      "tiktoken version: 0.11.0\n",
      "tokenizers version: 0.22.0\n",
      "tensorflow version: 2.20.0\n",
      "matplotlib version: 3.10.5\n",
      "huggingface_hub version: 0.34.4\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"tqdm\",\n",
    "    \"numpy\",\n",
    "    \"torch\",\n",
    "    \"pandas\",\n",
    "    \"tiktoken\",\n",
    "    \"tokenizers\",\n",
    "    \"tensorflow\",\n",
    "    \"matplotlib\",\n",
    "    \"huggingface_hub\",  \n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd27302",
   "metadata": {},
   "source": [
    "一、编写 GPT-small（124M）架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # 词汇表维度\n",
    "    \"context_length\": 256, # 上下文长度\n",
    "    \"emb_dim\": 768,         # 编码维度\n",
    "    \"n_heads\": 12,          # 注意力头数\n",
    "    \"n_layers\": 12,         # transformer 层数\n",
    "    \"drop_rate\": 0.1,       # 丢弃率\n",
    "    \"qkv_bias\": False       # k、q、v 偏置\n",
    "}\n",
    "# 归一化层 \n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "# GELU 激活函数\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "# 前馈网络\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "# 多头注意力\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x) \n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec\n",
    "    \n",
    "# transformer 块\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "# 模型架构\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b120f61",
   "metadata": {},
   "source": [
    "二、实体化模型，不加载预训练的权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4b07c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren Mortgage TT remember gard ACTIONSussedOND Land Engeleddedemate breaths proxies GalaxyForm therapies drying consultants FrazierVPN\n",
      "Output text:\n",
      " Who are you? Wisdom Stores instability firepoweromblehem  Barron expression Floating circumcision TT Telegram tweakingAllen lifelong systemic salt Tek accountedud sharp exacerbate discusses FE hammeredipal keepsiesel Tarant\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "torch.manual_seed(123)#代码设置了一个随机种子，确保可复现\n",
    "model = GPTModel(GPT_CONFIG_124M)#模型实体化\n",
    "model.eval();#设置为评估模式\n",
    "\n",
    "#定义两个转化函数：\n",
    "#将文本转换为tokenID\n",
    "def text_to_token_ids(text,tokenizer):\n",
    "    encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "#将tokenID转换为文本\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"#提示词\n",
    "start_context_1 = \"Who are you?\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")#初始化分词器\n",
    "\n",
    "#获取模型输出的tokenID并用分词器进行解码，返回文本信息\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context,tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context_1,tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c712f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Total number of parameter:162,419,712\n",
      "Total number of unique parameters:123,822,336\n",
      "float32 (Pytorch default): 1.21 GB\n",
      "bfloat16: 0.61 GB\n"
     ]
    }
   ],
   "source": [
    "# 可用设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "with device:\n",
    "    model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "# 计算模型中所有可训练参数的元素总数\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameter:{total_params:,}\")#冒号后面加逗号是格式说明符，作用是千位分隔符\n",
    "# 减去词嵌入共享的参数，输入词嵌入层 (tok_emb) 和输出的分类头 (out_head) 共享同一套权重矩阵，上一步的计算中重复了这部分数量\n",
    "total_params_normalized = total_params - model.tok_emb.weight.numel()\n",
    "print(f\"Total number of unique parameters:{total_params_normalized:,}\")\n",
    "\n",
    "#计算模型显存占用\n",
    "def model_memory_size(model,input_dtype=torch.float32):\n",
    "    #初始化参数和梯度的元素计数器\n",
    "    total_params = 0\n",
    "    total_grads = 0\n",
    "    #遍历所有模型参数\n",
    "    for param in model.parameters():\n",
    "        param_size = param.numel()\n",
    "        total_params += param_size\n",
    "\n",
    "        if param.requires_grad:\n",
    "            total_grads += param_size\n",
    "    #计算所有缓冲区的元素总数\n",
    "    total_buffers = sum(buf.numel() for buf in model.buffers())\n",
    "    #获取指定数据类型单个元素的大小\n",
    "    element_size = torch.tensor(0,dtype=input_dtype).element_size()\n",
    "    #计算总字节数\n",
    "    # 这里将 参数元素数 + 梯度元素数 + 缓冲区元素数 相加，再乘以每个元素的大小\n",
    "    total_memory_bytes = (total_params + total_grads +total_buffers) * element_size\n",
    "    #转换为GB单位\n",
    "    total_memory_gb = total_memory_bytes / (1024**3)\n",
    "    return total_memory_gb\n",
    "\n",
    "print(f\"float32 (Pytorch default): {model_memory_size(model,input_dtype=torch.float32):.2f} GB\")\n",
    "print(f\"bfloat16: {model_memory_size(model,input_dtype=torch.bfloat16):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeed41d",
   "metadata": {},
   "source": [
    "三、加载预训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca37e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n",
      "Characters: 20479\n",
      "Token: 5145\n",
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path,\"r\",encoding='utf-8') as file:\n",
    "        text_data = file.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(text_data[:99])\n",
    "print(text_data[-99:])\n",
    "print(\"Characters:\",total_characters)\n",
    "print(\"Token:\",total_tokens)\n",
    "#分割数据集，90%作为训练数据集，10%作为验证数据集\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))#计算数据集分割点\n",
    "train_data = text_data[:split_idx]#训练数据\n",
    "val_data = text_data[split_idx:]#验证数据\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#创建训练数据加载器\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,#如果最后剩下的数据不够一个batch，就丢弃\n",
    "    shuffle=True,#在每个epoch前打乱数据顺序，增强模型泛化能力\n",
    "    num_workers=0\n",
    ")\n",
    "#创建验证数据加载器\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,#不丢弃数据\n",
    "    shuffle=False,#不打乱数据\n",
    "    num_workers=0\n",
    ")\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokend for the training loader.\"\n",
    "          \"Try to lower the 'GPT_CONFIG_124M['context_length']' or\"\n",
    "          \"increase the 'training_ratio'\")\n",
    "    \n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader.\"\n",
    "          \"Try to lower the 'GPT_CONFIG_124M['context_length']' or\"\n",
    "          \"decrease the 'train_ratio'\")\n",
    "#计算训练集和验证集的token数\n",
    "train_tokens = 0\n",
    "for input_batch,target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch,target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\",train_tokens)\n",
    "print(\"Validation tokens:\",val_tokens)\n",
    "print(\"All tokens:\",train_tokens+val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314d2fc",
   "metadata": {},
   "source": [
    "四、计算在当前数据集上的 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3c832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.962354024251303\n",
      "Validation loss: 10.953326225280762\n"
     ]
    }
   ],
   "source": [
    "#函数：计算单个批次的损失\n",
    "def calc_loss_batch(input_batch,target_batch,model,device):\n",
    "    input_batch,target_batch = input_batch.to(device),target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
    "    return loss\n",
    "#函数：计算整个数据加载器的平均损失\n",
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "    for i,(input_batch,target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "#计算模型当前对训练数据集和验证数据集的损失，进行评估，并非训练阶段，因此无需计算梯度更新模型权重\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader,model,device)\n",
    "    val_loss = calc_loss_loader(val_loader,model,device)\n",
    "#当前模型对两个数据集的损失都很大，模型此时的性能很差\n",
    "print(\"Training loss:\",train_loss)\n",
    "print(\"Validation loss:\",val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7112f",
   "metadata": {},
   "source": [
    "五、对 LLM 进行预训练——学习通用的语言能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae9a812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1(Step000000):Train loss 9.820, Val loss 9.927\n",
      "Ep 1(Step000005):Train loss 8.066, Val loss 8.338\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2(Step000010):Train loss 6.624, Val loss 7.050\n",
      "Ep 2(Step000015):Train loss 6.049, Val loss 6.603\n",
      "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
      "Ep 3(Step000020):Train loss 5.559, Val loss 6.494\n",
      "Ep 3(Step000025):Train loss 5.428, Val loss 6.384\n",
      "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had, and, and, and, and, and, and, and, and, and,\n",
      "Ep 4(Step000030):Train loss 4.974, Val loss 6.285\n",
      "Ep 4(Step000035):Train loss 4.721, Val loss 6.303\n",
      "Every effort moves you of the picture.      \"I                \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5(Step000040):Train loss 4.058, Val loss 6.159\n",
      "Every effort moves you know the                          \"Oh, and the fact a little the latter the honour his pictures--and it's--I he had\n",
      "Ep 6(Step000045):Train loss 3.676, Val loss 6.174\n",
      "Ep 6(Step000050):Train loss 3.117, Val loss 6.148\n",
      "Every effort moves you know the fact, and pushed one of the to the fact of the last word.        \"Oh, and I was his pictures--I had the donkey. I had the donkey. \"I looked. \n",
      "Ep 7(Step000055):Train loss 3.026, Val loss 6.182\n",
      "Ep 7(Step000060):Train loss 2.281, Val loss 6.145\n",
      "Every effort moves you know,\" was not that the picture.  I-chairs forward. \"There: \"Yes, and!  \"I didn't say, and I was a little. \"I he was his pictures--because he was his pictures\n",
      "Ep 8(Step000065):Train loss 1.863, Val loss 6.164\n",
      "Ep 8(Step000070):Train loss 1.532, Val loss 6.259\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, and Mrs. I remember getting off a prod, as once one had been the donkey. \"There were days when I\n",
      "Ep 9(Step000075):Train loss 1.181, Val loss 6.249\n",
      "Ep 9(Step000080):Train loss 0.900, Val loss 6.266\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the honour being _mine_--because he's. The\n",
      "Ep 10(Step000085):Train loss 0.658, Val loss 6.369\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "def train_model_simple(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq,eval_iter,start_context,tokenizer):\n",
    "    #初始化记录器\n",
    "    train_losses,val_losses,track_tokens_seen = [],[],[]\n",
    "    tokens_seen,global_step = 0,-1\n",
    "    #外层循环：训练轮数\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        #内层循环：批次\n",
    "        for input_batch,target_batch in train_loader:\n",
    "            #把梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            #前向传播，计算损失\n",
    "            loss = calc_loss_batch(input_batch,target_batch,model,device)\n",
    "            #反向传播，计算梯度\n",
    "            loss.backward()\n",
    "            #更新模型权重\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            #每经过一定批次（eval_freq），就用验证数据集对模型进行一次评估\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss,val_loss = evaluate_model(model,train_loader,val_loader,device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1}(Step{global_step:06d}):\"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        generate_and_print_sample(model,tokenizer,device,start_context)\n",
    "\n",
    "    return train_losses,val_losses,track_tokens_seen\n",
    "\n",
    "#函数：评估模型表现\n",
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    #切换到评估模式\n",
    "    model.eval()\n",
    "    #无需更新梯度，计算模型在两个数据集上的损失\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "    #切换到训练模式\n",
    "    model.train()\n",
    "    return train_loss,val_loss\n",
    "\n",
    "#函数：生成样本\n",
    "def generate_and_print_sample(model,tokenizer,device,start_context):\n",
    "    #评估模式\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context,tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids,tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\",\" \"))#打印生成的文本信息\n",
    "    #训练模式\n",
    "    model.train()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay=0.1)#lr：学习率；weight_decay:正则化技术，防止模型过拟合\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses,val_losses,tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,#评估的频率,单位batch\n",
    "    eval_iter=5,#评估的数据量，单位batch\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae244ca4",
   "metadata": {},
   "source": [
    "六、绘制 loss 图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5b9ba9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\\\n",
    "#函数：将损失绘制为一幅图\n",
    "def plot_losses(epochs_seen,tokens_seen,train_losses,val_losses):\n",
    "    #创建图标和坐标轴\n",
    "    fig,ax1 = plt.subplots(figsize=(5,3))\n",
    "    #在第一个坐标轴 ax1 上绘制损失曲线\n",
    "    ax1.plot(epochs_seen,train_losses,label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen,val_losses,linestyle='-.',label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    #创建共享 Y 轴的第二个 X 轴\n",
    "    ax2 = ax1.twiny()\n",
    "    #在第二个坐标轴 ax2 上绘制一个“隐形”的图，用于设置刻度\n",
    "    ax2.plot(tokens_seen,train_losses,alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    #调整布局并显示/保存\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0,num_epochs,len(train_losses))\n",
    "plot_losses(epochs_tensor,tokens_seen,train_losses,val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "823496c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1)Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "He laughed again, and\n",
      "(2)Output text:\n",
      " Who are you? I'd never touched a brush.\"\n",
      "\n",
      "\"I told Mrs.\n",
      "\n",
      "\"Once, when I looked up, I seemed to see a smile\n"
     ]
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\",tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"(1)Output text:\\n\",token_ids_to_text(token_ids,tokenizer))\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Who are you?\",tokenizer),\n",
    "    max_new_tokens=30,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"(2)Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
